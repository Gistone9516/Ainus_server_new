/**
 * GPT ë¶„ë¥˜ ê²°ê³¼ë¥¼ MySQLì— ì €ì¥
 * - Clusters: í˜„ì¬ í´ëŸ¬ìŠ¤í„° ìƒíƒœ ìœ ì§€
 * - Cluster_Snapshots: ë§¤ ìˆ˜ì§‘ ì‹œì ì˜ í´ëŸ¬ìŠ¤í„° ìŠ¤ëƒ…ìƒ· ê¸°ë¡ (í™œì„± + ë¹„í™œì„±)
 */

import { executeQuery, executeModify, getDatabasePool } from "../../database/mysql";
import { PoolConnection } from "mysql2/promise";

// ============ Type ì •ì˜ ============

interface HistoryEntry {
  collected_at: string;
  article_indices: number[];
  article_count: number;
}

interface ClusterDocument {
  cluster_id: string;
  topic_name: string;
  tags: string[]; // JSON parsed
  appearance_count: number;
  status: "active" | "inactive";
  history: HistoryEntry[]; // Derived from cluster_history table
  created_at: string;
  updated_at: string;
}

interface ClusterSnapshot {
  collected_at: string;
  cluster_id: string;
  topic_name: string;
  tags: string[];
  appearance_count: number;
  article_count: number;
  article_indices: number[];
  status: "active" | "inactive";
  cluster_score: number;
}

interface GPTClusterOutput {
  cluster_id: string;
  topic_name: string;
  tags: string[];
  article_indices: number[];
  article_count: number;
  appearance_count: number;
}

interface GPTClassificationResult {
  clusters: GPTClusterOutput[];
  raw_response: string;
  processed_at: string;
}

// ============ í—¬í¼ í•¨ìˆ˜ ============

/**
 * ê¸°ì¡´ í´ëŸ¬ìŠ¤í„° ì¡°íšŒ
 */
async function getExistingClusters(): Promise<ClusterDocument[]> {
  // 1. Fetch clusters
  const clustersSql = `
    SELECT * FROM clusters
  `;
  const clusters = await executeQuery<any>(clustersSql);

  // 2. Fetch history for each cluster (Optimization: could be done with JOIN or separate query per cluster if needed, 
  // but for now assuming reasonable number of clusters, we can fetch all history or just fetch on demand.
  // However, the original logic requires full history to be present in the object.
  // Let's fetch recent history or just keep it simple. 
  // The original code stored history in the document. Here it's in a separate table.
  // For the purpose of 'updateExistingCluster', we just need to append to history table.
  // We don't necessarily need to load all history into memory unless we use it.
  // Looking at usage: 'updateExistingCluster' appends to history.
  // So we can just return the cluster info without full history for now, 
  // or fetch history if strictly needed.
  // The 'ClusterDocument' interface has 'history'. Let's populate it.

  const result: ClusterDocument[] = [];

  for (const row of clusters) {
    // Fetch history
    const historySql = `
      SELECT collected_at, article_indices, article_count 
      FROM cluster_history 
      WHERE cluster_id = ? 
      ORDER BY collected_at DESC
    `;
    const historyRows = await executeQuery<any>(historySql, [row.cluster_id]);

    const history: HistoryEntry[] = historyRows.map((h: any) => ({
      collected_at: h.collected_at instanceof Date ? h.collected_at.toISOString() : h.collected_at,
      article_indices: typeof h.article_indices === 'string' ? JSON.parse(h.article_indices) : h.article_indices,
      article_count: h.article_count
    }));

    result.push({
      cluster_id: row.cluster_id,
      topic_name: row.topic_name,
      tags: typeof row.tags === 'string' ? JSON.parse(row.tags) : row.tags,
      appearance_count: row.appearance_count,
      status: row.status,
      history: history,
      created_at: row.created_at instanceof Date ? row.created_at.toISOString() : row.created_at,
      updated_at: row.updated_at instanceof Date ? row.updated_at.toISOString() : row.updated_at,
    });
  }

  return result;
}

/**
 * ê¸°ì¡´ í´ëŸ¬ìŠ¤í„°ë¥¼ Mapìœ¼ë¡œ ë³€í™˜ (ë¹ ë¥¸ ì¡°íšŒìš©)
 */
function createClusterMap(
  clusters: ClusterDocument[]
): Map<string, ClusterDocument> {
  const map = new Map<string, ClusterDocument>();
  clusters.forEach((cluster) => {
    map.set(cluster.cluster_id, cluster);
  });
  return map;
}

/**
 * í´ëŸ¬ìŠ¤í„° ì ìˆ˜ ê³„ì‚° (ë¡œê·¸ í•¨ìˆ˜ ê¸°ë°˜)
 * ê³µì‹: 20 + (80 Ã— log(appearance_count)) / log(720)
 * - ì´ˆê¸°ê°’: 20ì  (appearance_count = 1)
 * - ìµœëŒ€ê°’: 100ì  (appearance_count = 720)
 */
function calculateClusterScore(appearanceCount: number): number {
  if (appearanceCount <= 0) {
    return 20;
  }
  return 20 + (80 * Math.log(appearanceCount)) / Math.log(720);
}

// ============ ì €ì¥ ë¡œì§ ============

/**
 * ê¸°ì¡´ í´ëŸ¬ìŠ¤í„° ì—…ë°ì´íŠ¸
 * - clusters í…Œì´ë¸” ì—…ë°ì´íŠ¸
 * - cluster_history í…Œì´ë¸”ì— ìƒˆ í•­ëª© ì¶”ê°€
 */
async function updateExistingCluster(
  connection: PoolConnection,
  existingCluster: ClusterDocument,
  gptCluster: GPTClusterOutput,
  collectedAt: string
): Promise<void> {
  // 1. Update clusters table
  const updateSql = `
    UPDATE clusters 
    SET 
      topic_name = ?, 
      tags = ?, 
      appearance_count = ?, 
      status = 'active', 
      updated_at = NOW()
    WHERE cluster_id = ?
  `;
  await connection.execute(updateSql, [
    gptCluster.topic_name,
    JSON.stringify(gptCluster.tags),
    gptCluster.appearance_count,
    gptCluster.cluster_id
  ]);

  // 2. Insert into cluster_history
  const historySql = `
    INSERT INTO cluster_history (cluster_id, collected_at, article_indices, article_count)
    VALUES (?, ?, ?, ?)
  `;
  await connection.execute(historySql, [
    gptCluster.cluster_id,
    collectedAt,
    JSON.stringify(gptCluster.article_indices),
    gptCluster.article_count
  ]);

  console.log(
    `   âœï¸  Updated cluster: ${gptCluster.cluster_id} (appearance: ${gptCluster.appearance_count})`
  );
}

/**
 * ìƒˆë¡œìš´ í´ëŸ¬ìŠ¤í„° ìƒì„±
 */
async function createNewCluster(
  connection: PoolConnection,
  gptCluster: GPTClusterOutput,
  collectedAt: string
): Promise<void> {
  // 1. Insert into clusters table
  const insertSql = `
    INSERT INTO clusters (cluster_id, topic_name, tags, appearance_count, status, created_at, updated_at)
    VALUES (?, ?, ?, ?, 'active', NOW(), NOW())
  `;
  await connection.execute(insertSql, [
    gptCluster.cluster_id,
    gptCluster.topic_name,
    JSON.stringify(gptCluster.tags),
    gptCluster.appearance_count
  ]);

  // 2. Insert into cluster_history
  const historySql = `
    INSERT INTO cluster_history (cluster_id, collected_at, article_indices, article_count)
    VALUES (?, ?, ?, ?)
  `;
  await connection.execute(historySql, [
    gptCluster.cluster_id,
    collectedAt,
    JSON.stringify(gptCluster.article_indices),
    gptCluster.article_count
  ]);

  console.log(`   âœ¨ Created new cluster: ${gptCluster.cluster_id}`);
}

/**
 * ë¹„í™œì„± í´ëŸ¬ìŠ¤í„° ì²˜ë¦¬
 * - GPT ì¶œë ¥ì— ì—†ëŠ” ê¸°ì¡´ í´ëŸ¬ìŠ¤í„°ë¥¼ inactiveë¡œ ë³€ê²½
 * - Cluster_Snapshotsì— ë¹„í™œì„± ê¸°ë¡ ì €ì¥
 */
async function deactivateMissingClusters(
  connection: PoolConnection,
  gptClusterIds: Set<string>,
  collectedAt: string
): Promise<void> {
  // Get active clusters that are NOT in gptClusterIds
  // We can do this by querying DB or filtering the 'existingClusters' we fetched earlier.
  // Let's use the DB to be safe and consistent within transaction if possible, 
  // but we need to iterate to insert snapshots.

  // Fetch currently active clusters
  const [activeRows] = await connection.execute<any>(`SELECT * FROM clusters WHERE status = 'active'`);

  for (const cluster of activeRows) {
    if (!gptClusterIds.has(cluster.cluster_id)) {
      // 1. Update status to inactive
      await connection.execute(
        `UPDATE clusters SET status = 'inactive', updated_at = NOW() WHERE cluster_id = ?`,
        [cluster.cluster_id]
      );

      // 2. Insert inactive snapshot
      const inactiveSnapshotSql = `
        INSERT INTO cluster_snapshots 
        (collected_at, cluster_id, topic_name, tags, appearance_count, article_count, article_indices, status, cluster_score)
        VALUES (?, ?, ?, ?, ?, 0, '[]', 'inactive', 0)
      `;
      await connection.execute(inactiveSnapshotSql, [
        collectedAt,
        cluster.cluster_id,
        cluster.topic_name,
        typeof cluster.tags === 'string' ? cluster.tags : JSON.stringify(cluster.tags),
        cluster.appearance_count
      ]);

      console.log(`   â›” Deactivated cluster: ${cluster.cluster_id}`);
    }
  }
}

/**
 * Cluster_Snapshotsì— í˜„ì¬ ìƒíƒœ ê¸°ë¡
 * - í™œì„± í´ëŸ¬ìŠ¤í„°ë§Œ ì €ì¥
 */
async function saveClusterSnapshots(
  connection: PoolConnection,
  gptClusters: GPTClusterOutput[],
  collectedAt: string
): Promise<void> {
  const sql = `
    INSERT INTO cluster_snapshots 
    (collected_at, cluster_id, topic_name, tags, appearance_count, article_count, article_indices, status, cluster_score)
    VALUES (?, ?, ?, ?, ?, ?, ?, 'active', ?)
  `;

  for (const cluster of gptClusters) {
    await connection.execute(sql, [
      collectedAt,
      cluster.cluster_id,
      cluster.topic_name,
      JSON.stringify(cluster.tags),
      cluster.appearance_count,
      cluster.article_count,
      JSON.stringify(cluster.article_indices),
      calculateClusterScore(cluster.appearance_count)
    ]);
  }

  console.log(`   ğŸ“¸ Saved ${gptClusters.length} cluster snapshots`);
}

// ============ ë©”ì¸ ì €ì¥ í•¨ìˆ˜ ============

/**
 * GPT ë¶„ë¥˜ ê²°ê³¼ë¥¼ DBì— ì €ì¥
 * 1. ê¸°ì¡´ í´ëŸ¬ìŠ¤í„° ì¡°íšŒ
 * 2. ê° GPT í´ëŸ¬ìŠ¤í„°ì— ëŒ€í•´:
 *    - ê¸°ì¡´ì´ë©´ â†’ update
 *    - ìƒˆê²ƒì´ë©´ â†’ create
 * 3. ë¹„í™œì„±í™”í•  í´ëŸ¬ìŠ¤í„° ì²˜ë¦¬
 * 4. Cluster_Snapshotsì— ê¸°ë¡ (í™œì„± + ë¹„í™œì„±)
 */
async function saveClassificationResultToDB(
  classificationResult: GPTClassificationResult
): Promise<void> {
  console.log("\n========== Saving Classification Results to DB (MySQL) ==========\n");

  const collectedAt = classificationResult.processed_at;
  const pool = getDatabasePool();
  const connection = await pool.getConnection();

  try {
    await connection.beginTransaction();

    // Step 1: ê¸°ì¡´ í´ëŸ¬ìŠ¤í„° ì¡°íšŒ (for logic check)
    console.log("ğŸ“š Fetching existing clusters...");
    const existingClusters = await getExistingClusters();
    const clusterMap = createClusterMap(existingClusters);
    console.log(
      `   âœ… Found ${existingClusters.length} existing clusters\n`
    );

    // Step 2: GPT í´ëŸ¬ìŠ¤í„° ì²˜ë¦¬
    console.log("ğŸ”„ Processing GPT clusters...");
    const gptClusterIds = new Set<string>();

    for (const gptCluster of classificationResult.clusters) {
      gptClusterIds.add(gptCluster.cluster_id);

      const existingCluster = clusterMap.get(gptCluster.cluster_id);

      if (existingCluster) {
        // ì—…ë°ì´íŠ¸
        await updateExistingCluster(connection, existingCluster, gptCluster, collectedAt);
      } else {
        // ìƒì„±
        await createNewCluster(connection, gptCluster, collectedAt);
      }
    }
    console.log("");

    // Step 3: ë¹„í™œì„±í™” ì²˜ë¦¬
    console.log("â›” Deactivating missing clusters...");
    await deactivateMissingClusters(connection, gptClusterIds, collectedAt);
    console.log("");

    // Step 4: Snapshots ì €ì¥ (í™œì„± í´ëŸ¬ìŠ¤í„°)
    console.log("ğŸ“¸ Saving cluster snapshots...");
    await saveClusterSnapshots(connection, classificationResult.clusters, collectedAt);
    console.log("");

    await connection.commit();
    console.log("âœ… DB save completed successfully!\n");

    // í†µê³„
    const updatedCount = classificationResult.clusters.filter((c) =>
      clusterMap.has(c.cluster_id)
    ).length;
    const createdCount = classificationResult.clusters.length - updatedCount;

    // Note: This deactivated count is an approximation based on what we fetched initially.
    // The actual deactivated count is logged in deactivateMissingClusters.
    const deactivatedCount = existingClusters.filter(c => c.status === 'active' && !gptClusterIds.has(c.cluster_id)).length;

    console.log("ğŸ“Š Summary:");
    console.log(`   - Updated: ${updatedCount}`);
    console.log(`   - Created: ${createdCount}`);
    console.log(`   - Deactivated: ${deactivatedCount}`);
    console.log(`   - Current active: ${classificationResult.clusters.length}`);

  } catch (error) {
    await connection.rollback();
    console.error("âŒ Error saving to DB:", error);
    throw error;
  } finally {
    connection.release();
  }
}

// ============ Export ============

export {
  saveClassificationResultToDB,
  calculateClusterScore,
  ClusterDocument,
  ClusterSnapshot,
  GPTClusterOutput,
  GPTClassificationResult,
};
