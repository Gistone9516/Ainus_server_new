/**
 * AI ë‰´ìŠ¤ í´ëŸ¬ìŠ¤í„°ë§ - ì§ì—…ë³„ ì´ìŠˆ ì§€ìˆ˜ DB ì €ì¥
 *
 * ì €ì¥ í”„ë¡œì„¸ìŠ¤:
 * 1. job_issue_index í…Œì´ë¸”ì— ì§ì—…ë³„ ì´ìŠˆ ì§€ìˆ˜ ì €ì¥
 * 2. job_cluster_mapping í…Œì´ë¸”ì— ë§¤ì¹­ëœ í´ëŸ¬ìŠ¤í„° ì •ë³´ ì €ì¥
 *
 * íŠ¸ëœì­ì…˜ìœ¼ë¡œ ë°ì´í„° ë¬´ê²°ì„± ë³´ì¥
 */

import { getDatabasePool } from '../../database/mysql';
import { Logger } from '../../database/logger';
import { PoolConnection, RowDataPacket } from 'mysql2/promise';

const logger = new Logger('SaveJobIssueIndex');

// ============ í—¬í¼ í•¨ìˆ˜ ============

/**
 * ISO 8601 ë¬¸ìì—´ì„ MySQL DATETIME í˜•ì‹ìœ¼ë¡œ ë³€í™˜
 * '2025-11-30T17:00:46.419Z' â†’ '2025-11-30 17:00:46'
 */
function toMySQLDatetime(isoString: string): string {
  const date = new Date(isoString);
  return date.toISOString().slice(0, 19).replace('T', ' ');
}

// ============ Type ì •ì˜ ============

interface ClusterMatch {
  cluster_id: string;
  cluster_score: number;
  status: 'active' | 'inactive';
  collected_at: string;
  matched_tags: string[];
  match_ratio: number;
  weighted_score: number;
}

interface JobIssueIndexResult {
  job_category: string;
  collected_at: string;
  issue_index: number;
  active_clusters_count: number;
  inactive_clusters_count: number;
  total_articles_count: number;
  cluster_matches: ClusterMatch[];
}

// ============ í—¬í¼ í•¨ìˆ˜ ============

/**
 * ì´ ê¸°ì‚¬ ê°œìˆ˜ ê³„ì‚° (ì¤‘ë³µ ì œê±°)
 * cluster_snapshotsì—ì„œ article_indicesë¥¼ ë³‘í•©í•˜ì—¬ ìœ ë‹ˆí¬í•œ ê¸°ì‚¬ ê°œìˆ˜ ê³„ì‚°
 */
async function calculateTotalArticlesCount(
  connection: PoolConnection,
  clusterMatches: ClusterMatch[],
  collectedAt: string
): Promise<number> {
  if (clusterMatches.length === 0) {
    return 0;
  }

  const clusterIds = clusterMatches.map((m) => m.cluster_id);
  const placeholders = clusterIds.map(() => '?').join(', ');

  const query = `
    SELECT article_indices
    FROM cluster_snapshots
    WHERE collected_at = ?
      AND cluster_id IN (${placeholders})
  `;

  const params = [toMySQLDatetime(collectedAt), ...clusterIds];
  const [rows] = await connection.query<RowDataPacket[]>(query, params);

  // ëª¨ë“  article_indicesë¥¼ ë³‘í•©í•˜ì—¬ ì¤‘ë³µ ì œê±°
  const allIndices = new Set<number>();

  for (const row of rows) {
    // article_indicesê°€ ì´ë¯¸ íŒŒì‹±ëœ ë°°ì—´ì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©, ë¬¸ìì—´ì´ë©´ íŒŒì‹±
    const indices: number[] = typeof row.article_indices === 'string'
      ? JSON.parse(row.article_indices)
      : row.article_indices;
    indices.forEach((index) => allIndices.add(index));
  }

  return allIndices.size;
}

/**
 * job_issue_index í…Œì´ë¸”ì— ì €ì¥
 */
async function saveJobIssueIndex(
  connection: PoolConnection,
  result: JobIssueIndexResult,
  totalArticlesCount: number
): Promise<void> {
  const query = `
    INSERT INTO job_issue_index (
      job_category,
      collected_at,
      issue_index,
      active_clusters_count,
      inactive_clusters_count,
      total_articles_count
    ) VALUES (?, ?, ?, ?, ?, ?)
    ON DUPLICATE KEY UPDATE
      issue_index = VALUES(issue_index),
      active_clusters_count = VALUES(active_clusters_count),
      inactive_clusters_count = VALUES(inactive_clusters_count),
      total_articles_count = VALUES(total_articles_count),
      created_at = CURRENT_TIMESTAMP
  `;

  const params = [
    result.job_category,
    toMySQLDatetime(result.collected_at),
    result.issue_index,
    result.active_clusters_count,
    result.inactive_clusters_count,
    totalArticlesCount,
  ];

  await connection.query(query, params);
  logger.info(`   âœ… Saved job_issue_index for "${result.job_category}"`);
}

/**
 * job_cluster_mapping í…Œì´ë¸”ì— ë§¤ì¹­ ì •ë³´ ì €ì¥ (ë°°ì¹˜ ì²˜ë¦¬)
 */
async function saveJobClusterMappings(
  connection: PoolConnection,
  jobCategory: string,
  collectedAt: string,
  clusterMatches: ClusterMatch[]
): Promise<void> {
  if (clusterMatches.length === 0) {
    logger.info(`   â„¹ï¸  No cluster matches to save for "${jobCategory}"`);
    return;
  }

  // ê¸°ì¡´ ë§¤í•‘ ì‚­ì œ (ë™ì¼ job_category, collected_at)
  const deleteQuery = `
    DELETE FROM job_cluster_mapping
    WHERE job_category = ? AND collected_at = ?
  `;
  await connection.query(deleteQuery, [jobCategory, toMySQLDatetime(collectedAt)]);

  // ë°°ì¹˜ ì‚½ì…
  const insertQuery = `
    INSERT INTO job_cluster_mapping (
      job_category,
      collected_at,
      cluster_id,
      match_ratio,
      weighted_score
    ) VALUES ?
  `;

  const mysqlDatetime = toMySQLDatetime(collectedAt);
  const values = clusterMatches.map((match) => [
    jobCategory,
    mysqlDatetime,
    match.cluster_id,
    match.match_ratio,
    match.weighted_score,
  ]);

  await connection.query(insertQuery, [values]);
  logger.info(
    `   âœ… Saved ${clusterMatches.length} cluster mappings for "${jobCategory}"`
  );
}

// ============ ë©”ì¸ í•¨ìˆ˜ ============

/**
 * ë‹¨ì¼ ì§ì—… ì¹´í…Œê³ ë¦¬ì˜ ì´ìŠˆ ì§€ìˆ˜ ì €ì¥
 */
export async function saveSingleJobIssueIndex(
  result: JobIssueIndexResult
): Promise<void> {
  const connection = await getDatabasePool().getConnection();

  try {
    await connection.beginTransaction();
    logger.info(`\nğŸ“¦ Saving job issue index for "${result.job_category}"...`);

    // Step 1: ì´ ê¸°ì‚¬ ê°œìˆ˜ ê³„ì‚°
    const totalArticlesCount = await calculateTotalArticlesCount(
      connection,
      result.cluster_matches,
      result.collected_at
    );
    logger.info(`   ğŸ“Š Total articles: ${totalArticlesCount}`);

    // Step 2: job_issue_index ì €ì¥
    await saveJobIssueIndex(connection, result, totalArticlesCount);

    // Step 3: job_cluster_mapping ì €ì¥
    await saveJobClusterMappings(
      connection,
      result.job_category,
      result.collected_at,
      result.cluster_matches
    );

    await connection.commit();
    logger.info(`   âœ… Transaction committed for "${result.job_category}"\n`);
  } catch (error) {
    await connection.rollback();
    logger.error(`Failed to save job issue index for "${result.job_category}"`, error);
    throw error;
  } finally {
    connection.release();
  }
}

/**
 * ëª¨ë“  ì§ì—… ì¹´í…Œê³ ë¦¬(13ê°œ)ì˜ ì´ìŠˆ ì§€ìˆ˜ ì €ì¥
 */
export async function saveAllJobIssueIndexes(
  results: JobIssueIndexResult[]
): Promise<void> {
  logger.info(
    `\n========== Saving All Job Issue Indexes (${results.length} jobs) ==========\n`
  );

  for (const result of results) {
    try {
      await saveSingleJobIssueIndex(result);
    } catch (error) {
      logger.error(`Failed to save job issue index for "${result.job_category}"`, error);
      throw error;
    }
  }

  logger.info(`\n========== All Job Issue Indexes Saved Successfully ==========\n`);
}
