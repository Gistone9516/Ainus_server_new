/**
 * ë‰´ìŠ¤ í´ëŸ¬ìŠ¤í„°ë§ íŒŒì´í”„ë¼ì¸ (MySQL ê¸°ë°˜)
 *
 * ì „ì²´ í”„ë¡œì„¸ìŠ¤:
 * 1. ì „ì²˜ë¦¬ (MySQLì—ì„œ ê¸°ì‚¬/í´ëŸ¬ìŠ¤í„° ì¡°íšŒ -> GPT ì…ë ¥ ìƒì„±)
 * 2. GPT ë¶„ë¥˜ (OpenAI API í˜¸ì¶œ)
 * 3. DB ì €ì¥ (MySQLì— ê²°ê³¼ ì €ì¥)
 * 4. ì´ìŠˆ ì§€ìˆ˜ ê³„ì‚° (MySQL ë°ì´í„° ê¸°ë°˜ ê³„ì‚°)
 * 5. ì´ìŠˆ ì§€ìˆ˜ ì €ì¥ (MySQL issue_index í…Œì´ë¸”ì— ì €ì¥)
 */

import cron from "node-cron";
import {
  preprocessGPTInputData,
  getActiveClustersFromDB,
  getRecentInactiveClustersFromDB,
  Cluster
} from "./gpt_input_preprocessing";
import { classifyNewsWithGPT } from "./gpt-classifier";
import {
  saveClassificationResultToDB,
  calculateClusterScore,
  ClusterSnapshot as DBClusterSnapshot
} from "./db-save";
import {
  calculateIssueIndex,
  IssueIndexInput,
  IssueIndexOutput
} from "./calculate-issue-index";
import { saveIssueIndexToMySQL } from "./save-issue-index";

// ============ ì„¤ì • ============

interface PipelineConfig {
  maxRetries: number;
  retryDelayMs: number;
  enableSchedule: boolean;
  scheduleTime: string; // cron í˜•ì‹
}

const DEFAULT_CONFIG: PipelineConfig = {
  retryDelayMs: 5000, // 5ì´ˆ
  maxRetries: 2,
  enableSchedule: true,
  scheduleTime: "0 * * * *", // ë§¤ ì‹œê°„ ì •ê°
};

interface PipelineResult {
  status: "success" | "failure";
  message: string;
  executedAt: string;
  duration: number;
  clusters_created: number;
  clusters_updated: number;
  issue_index: number;
  error?: string;
}

// ============ í—¬í¼ í•¨ìˆ˜ ============

function delay(ms: number): Promise<void> {
  return new Promise((resolve) => setTimeout(resolve, ms));
}

function getNextExecutionTime(): string {
  const now = new Date();
  now.setHours(now.getHours() + 1);
  now.setMinutes(0);
  now.setSeconds(0);
  now.setMilliseconds(0);
  return now.toISOString();
}

/**
 * Cluster ê°ì²´ë¥¼ IssueIndexInputìš© ClusterSnapshotìœ¼ë¡œ ë³€í™˜
 */
function mapToClusterSnapshot(cluster: Cluster): any {
  // calculate-issue-index.tsì˜ ClusterSnapshot ì¸í„°í˜ì´ìŠ¤ì— ë§ì¶¤
  return {
    cluster_id: cluster.cluster_id,
    topic_name: cluster.topic_name,
    tags: cluster.tags,
    appearance_count: cluster.appearance_count,
    article_count: 0, // ê³„ì‚°ì— ì§ì ‘ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ (ì ìˆ˜ ê³„ì‚°ì€ appearance_count ê¸°ë°˜)
    article_indices: [],
    status: cluster.status,
    cluster_score: calculateClusterScore(cluster.appearance_count),
    collected_at: cluster.updated_at // ìµœê·¼ ì—…ë°ì´íŠ¸ ì‹œê°„ì„ ìˆ˜ì§‘ ì‹œê°„ìœ¼ë¡œ ê°„ì£¼
  };
}

// ============ ë©”ì¸ íŒŒì´í”„ë¼ì¸ ============

async function executePipelineWithRetry(
  retryCount: number = 0,
  maxRetries: number = DEFAULT_CONFIG.maxRetries
): Promise<PipelineResult> {
  console.log("\n" + "=".repeat(70));
  console.log("ğŸš€ News Clustering Pipeline Started (MySQL)");
  console.log("=".repeat(70));
  console.log(`â° Timestamp: ${new Date().toISOString()}`);
  console.log(`ğŸ”„ Attempt: ${retryCount + 1}/${maxRetries + 1}\n`);

  const startTime = Date.now();

  try {
    // ========== Step 1: ì „ì²˜ë¦¬ ==========
    console.log("ğŸ“‹ [Step 1/4] Data Preprocessing...\n");

    const gptInput = await preprocessGPTInputData();
    console.log(`âœ… Preprocessing complete\n`);

    // ========== Step 2: GPT ë¶„ë¥˜ ==========
    console.log("ğŸ¤– [Step 2/4] GPT Classification...\n");

    const classificationResult = await classifyNewsWithGPT(gptInput);
    console.log(`âœ… Classification complete\n`);

    // ========== Step 3: DB ì €ì¥ ==========
    console.log("ğŸ’¾ [Step 3/4] Saving to Databases...\n");

    await saveClassificationResultToDB(classificationResult);
    console.log(`âœ… DB save complete\n`);

    // ========== Step 4: ì´ìŠˆ ì§€ìˆ˜ ê³„ì‚° & ì €ì¥ ==========
    console.log("ğŸ“Š [Step 4/4] Calculating Issue Index...\n");

    // DB ìƒíƒœê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìœ¼ë¯€ë¡œ ë‹¤ì‹œ ì¡°íšŒí•˜ì—¬ ìµœì‹  ìƒíƒœ ë°˜ì˜
    const activeClusters = await getActiveClustersFromDB();
    const inactiveClusters = await getRecentInactiveClustersFromDB();

    const issueIndexInput: IssueIndexInput = {
      active_clusters: activeClusters.map(mapToClusterSnapshot),
      inactive_clusters_within_30days: inactiveClusters.map(mapToClusterSnapshot),
      calculated_at: new Date().toISOString(),
    };

    const issueIndexOutput = calculateIssueIndex(issueIndexInput);

    await saveIssueIndexToMySQL({
      collected_at: issueIndexOutput.collected_at,
      overall_index: issueIndexOutput.overall_index,
      active_clusters_count: issueIndexOutput.active_count,
      inactive_clusters_count: issueIndexOutput.inactive_count,
      total_articles_analyzed: gptInput.new_articles.length // ì´ë²ˆì— ë¶„ì„í•œ ê¸°ì‚¬ ìˆ˜
    });
    console.log(`âœ… Issue index calculation complete\n`);

    const duration = Date.now() - startTime;

    // í†µê³„ ê³„ì‚°
    const processedClusters = classificationResult.clusters.length;

    const result: PipelineResult = {
      status: "success",
      message: "Pipeline executed successfully",
      executedAt: new Date().toISOString(),
      duration,
      clusters_created: 0, // ìƒì„¸ í†µê³„ëŠ” ë¡œê·¸ ì°¸ì¡°
      clusters_updated: processedClusters,
      issue_index: issueIndexOutput.overall_index,
    };

    // ========== ì™„ë£Œ ë¡œê·¸ ==========
    console.log("=".repeat(70));
    console.log("âœ… Pipeline Completed Successfully");
    console.log("=".repeat(70));
    console.log(`â±ï¸  Duration: ${duration}ms (${(duration / 1000).toFixed(2)}s)`);
    console.log(`ğŸ“Š Summary:`);
    console.log(`   - Clusters processed: ${processedClusters}`);
    console.log(`   - Issue index: ${result.issue_index}`);
    console.log(`ğŸ“… Next execution: ${getNextExecutionTime()}\n`);

    return result;
  } catch (error) {
    console.error("\nâŒ Pipeline Error:", error);

    if (retryCount < maxRetries) {
      console.log(
        `\nâ³ Retrying in ${DEFAULT_CONFIG.retryDelayMs}ms...`
      );
      await delay(DEFAULT_CONFIG.retryDelayMs);
      return executePipelineWithRetry(retryCount + 1, maxRetries);
    }

    const duration = Date.now() - startTime;

    const result: PipelineResult = {
      status: "failure",
      message: `Pipeline failed after ${maxRetries + 1} attempts`,
      executedAt: new Date().toISOString(),
      duration,
      clusters_created: 0,
      clusters_updated: 0,
      issue_index: 0,
      error: error instanceof Error ? error.message : String(error),
    };

    console.log("=".repeat(70));
    console.log("âŒ Pipeline Failed");
    console.log("=".repeat(70));

    return result;
  }
}

// ============ ìŠ¤ì¼€ì¤„ëŸ¬ ==========

let scheduledJob: any = null;

/**
 * íŒŒì´í”„ë¼ì¸ ìŠ¤ì¼€ì¤„ ì‹œì‘
 */
function startScheduler(config: Partial<PipelineConfig> = {}): void {
  const finalConfig = { ...DEFAULT_CONFIG, ...config };

  if (!finalConfig.enableSchedule) {
    console.log("â­ï¸  Schedule is disabled. Pipeline will run manually only.");
    return;
  }

  console.log("\n" + "=".repeat(70));
  console.log("ğŸ“… News Clustering Pipeline Scheduler Started");
  console.log("=".repeat(70));
  console.log(`â° Schedule: ${finalConfig.scheduleTime} (every hour)`);
  console.log(`ğŸ”„ Max retries: ${finalConfig.maxRetries}`);
  console.log(`â³ Retry delay: ${finalConfig.retryDelayMs}ms\n`);

  // cron í˜•ì‹: "0 * * * *" = ë§¤ ì‹œê°„ ì •ê°
  scheduledJob = cron.schedule(finalConfig.scheduleTime, () => {
    executePipelineWithRetry(0, finalConfig.maxRetries);
  });

  console.log("âœ… Scheduler is running. Next execution: " + getNextExecutionTime());
}

/**
 * íŒŒì´í”„ë¼ì¸ ìŠ¤ì¼€ì¤„ ì¤‘ì§€
 */
function stopScheduler(): void {
  if (scheduledJob) {
    scheduledJob.stop();
    scheduledJob = null;
    console.log("â¹ï¸  Scheduler stopped");
  }
}

/**
 * íŒŒì´í”„ë¼ì¸ ìˆ˜ë™ ì‹¤í–‰
 */
async function runPipelineManually(): Promise<PipelineResult> {
  return executePipelineWithRetry(0, DEFAULT_CONFIG.maxRetries);
}

// ============ Export ============

export {
  startScheduler,
  stopScheduler,
  runPipelineManually,
  executePipelineWithRetry,
  getNextExecutionTime,
  PipelineConfig,
  PipelineResult,
};
