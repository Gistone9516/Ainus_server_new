/**
 * ë‰´ìŠ¤ ê¸°ì‚¬ ë°ì´í„°ë² ì´ìŠ¤ ì•¡ì„¸ìŠ¤ (MySQL ê¸°ë°˜)
 *
 * ì—­í• :
 * - news_articles í…Œì´ë¸”ì—ì„œ ê¸°ì‚¬ ì¡°íšŒ
 * - í¬ë¡¤ëŸ¬ìš© ê¸°ì‚¬ ì €ì¥ í•¨ìˆ˜ ì œê³µ
 * - Redis ìºì‹±ì„ í†µí•œ ì„±ëŠ¥ ìµœì í™”
 */

import { getDatabasePool } from './mysql';
import { getRedisCache } from './redis';
import { PoolConnection } from 'mysql2/promise';

/**
 * ê¸°ì‚¬ ë°ì´í„° íƒ€ì…
 */
export interface Article {
  index: number;          // 0-999
  title: string;
  link: string;
  description: string;
  pubDate: string;        // ISO 8601 í˜•ì‹
}

/**
 * DBì—ì„œ ì¡°íšŒí•œ ê¸°ì‚¬ íƒ€ì… (article_id í¬í•¨)
 */
export interface ArticleFromDB extends Article {
  article_id: number;
  collected_at: string;
  source: string;
}

/**
 * íŠ¹ì • ì‹œê°„ì˜ íŠ¹ì • ì¸ë±ìŠ¤ ê¸°ì‚¬ë“¤ ì¡°íšŒ (Redis ìºì‹± ì ìš©)
 *
 * @param collectedAt - ìˆ˜ì§‘ ì‹œê°„ (ISO 8601 í˜•ì‹)
 * @param indices - ê¸°ì‚¬ ì¸ë±ìŠ¤ ë°°ì—´ (ì˜ˆ: [0, 4, 15, 67])
 * @returns ê¸°ì‚¬ ë°°ì—´
 */
export async function getArticlesByIndices(
  collectedAt: string,
  indices: number[]
): Promise<Article[]> {
  if (!collectedAt || indices.length === 0) {
    return [];
  }

  const redis = getRedisCache();
  const sortedIndices = [...indices].sort((a, b) => a - b);
  const cacheKey = `articles:${collectedAt}:${sortedIndices.join(',')}`;

  try {
    // 1. Redis ìºì‹œ í™•ì¸
    const cached = await redis.get(cacheKey);
    if (cached) {
      console.log(`âœ… Cache HIT for ${collectedAt} indices ${sortedIndices.slice(0, 3).join(',')}...`);
      return JSON.parse(cached);
    }

    console.log(`âš ï¸  Cache MISS for ${collectedAt}, fetching from MySQL...`);

    // 2. MySQL ì¡°íšŒ
    const pool = getDatabasePool();
    const connection = await pool.getConnection();

    try {
      const placeholders = indices.map(() => '?').join(',');

      const [rows] = await connection.execute(
        `SELECT
          article_index as \`index\`,
          title,
          link,
          description,
          pub_date as pubDate
        FROM news_articles
        WHERE collected_at = ? AND article_index IN (${placeholders})
        ORDER BY article_index ASC`,
        [collectedAt, ...indices]
      );

      const articles = (rows as any[]).map((row) => ({
        index: row.index,
        title: row.title,
        link: row.link,
        description: row.description || '',
        pubDate: row.pubDate ? new Date(row.pubDate).toISOString() : ''
      }));

      // 3. Redisì— ìºì‹± (1ì‹œê°„ TTL)
      await redis.set(cacheKey, JSON.stringify(articles), 3600);
      console.log(`ğŸ’¾ Cached ${articles.length} articles for 1 hour`);

      return articles;
    } finally {
      connection.release();
    }
  } catch (error) {
    console.error('âŒ Error fetching articles by indices:', error);
    throw error;
  }
}

/**
 * íŠ¹ì • ì‹œê°„ì˜ ëª¨ë“  ê¸°ì‚¬ ì¡°íšŒ (Redis ìºì‹± ì ìš©)
 *
 * @param collectedAt - ìˆ˜ì§‘ ì‹œê°„ (ISO 8601 í˜•ì‹)
 * @returns ê¸°ì‚¬ ë°°ì—´
 */
export async function getArticlesByCollectedAt(
  collectedAt: string
): Promise<ArticleFromDB[]> {
  if (!collectedAt) {
    return [];
  }

  const redis = getRedisCache();
  const cacheKey = `articles:all:${collectedAt}`;

  try {
    // 1. Redis ìºì‹œ í™•ì¸
    const cached = await redis.get(cacheKey);
    if (cached) {
      console.log(`âœ… Cache HIT for all articles at ${collectedAt}`);
      return JSON.parse(cached);
    }

    console.log(`âš ï¸  Cache MISS for ${collectedAt}, fetching all articles from MySQL...`);

    // 2. MySQL ì¡°íšŒ
    const pool = getDatabasePool();
    const connection = await pool.getConnection();

    try {
      const [rows] = await connection.execute(
        `SELECT
          article_id,
          collected_at,
          article_index as \`index\`,
          source,
          title,
          link,
          description,
          pub_date as pubDate
        FROM news_articles
        WHERE collected_at = ?
        ORDER BY article_index ASC`,
        [collectedAt]
      );

      const articles = (rows as any[]).map((row) => ({
        article_id: row.article_id,
        collected_at: row.collected_at,
        index: row.index,
        source: row.source,
        title: row.title,
        link: row.link,
        description: row.description || '',
        pubDate: row.pubDate ? new Date(row.pubDate).toISOString() : ''
      }));

      // 3. Redisì— ìºì‹± (1ì‹œê°„ TTL)
      await redis.set(cacheKey, JSON.stringify(articles), 3600);
      console.log(`ğŸ’¾ Cached ${articles.length} articles for 1 hour`);

      return articles;
    } finally {
      connection.release();
    }
  } catch (error) {
    console.error('âŒ Error fetching articles by collected_at:', error);
    throw error;
  }
}

/**
 * ìµœì‹  ìˆ˜ì§‘ ì‹œê°„ ì¡°íšŒ (Redis ìºì‹± ì ìš©)
 *
 * @returns ìµœì‹  ìˆ˜ì§‘ ì‹œê°„ (ISO 8601 í˜•ì‹) ë˜ëŠ” null
 */
export async function getLatestCollectedAt(): Promise<string | null> {
  const redis = getRedisCache();
  const cacheKey = 'articles:latest_collected_at';

  try {
    // 1. Redis ìºì‹œ í™•ì¸
    const cached = await redis.get(cacheKey);
    if (cached) {
      return cached;
    }

    // 2. MySQL ì¡°íšŒ
    const pool = getDatabasePool();
    const connection = await pool.getConnection();

    try {
      const [rows] = await connection.execute(
        `SELECT MAX(collected_at) as latest FROM news_articles`
      );

      const latest = (rows as any[])[0]?.latest;

      if (!latest) {
        return null;
      }

      const latestISO = new Date(latest).toISOString();

      // 3. Redisì— ìºì‹± (5ë¶„ TTL)
      await redis.set(cacheKey, latestISO, 300);

      return latestISO;
    } finally {
      connection.release();
    }
  } catch (error) {
    console.error('âŒ Error fetching latest collected_at:', error);
    throw error;
  }
}

/**
 * ê¸°ì‚¬ ì¼ê´„ ì €ì¥ (í¬ë¡¤ëŸ¬ìš©)
 *
 * íŠ¸ëœì­ì…˜ì„ ì‚¬ìš©í•˜ì—¬ ì›ìì„± ë³´ì¥
 * ON DUPLICATE KEY UPDATEë¡œ ì¤‘ë³µ ì²˜ë¦¬
 *
 * @param collectedAt - ìˆ˜ì§‘ ì‹œê°„ (ISO 8601 í˜•ì‹)
 * @param articles - ê¸°ì‚¬ ë°°ì—´ (1000ê°œ)
 * @param source - ì¶œì²˜ (ê¸°ë³¸ê°’: 'naver')
 */
export async function saveArticles(
  collectedAt: string,
  articles: Article[],
  source: string = 'naver'
): Promise<void> {
  const pool = getDatabasePool();
  const connection = await pool.getConnection();

  try {
    await connection.beginTransaction();

    console.log(`ğŸ’¾ Saving ${articles.length} articles for ${collectedAt}...`);

    for (const article of articles) {
      await connection.execute(
        `INSERT INTO news_articles
         (collected_at, article_index, source, title, link, description, pub_date)
         VALUES (?, ?, ?, ?, ?, ?, ?)
         ON DUPLICATE KEY UPDATE
           title = VALUES(title),
           link = VALUES(link),
           description = VALUES(description),
           pub_date = VALUES(pub_date)`,
        [
          collectedAt,
          article.index,
          source,
          article.title,
          article.link,
          article.description || '',
          article.pubDate
        ]
      );
    }

    await connection.commit();
    console.log(`âœ… Saved ${articles.length} articles to MySQL`);

    // Redis ìºì‹œ ë¬´íš¨í™”
    const redis = getRedisCache();
    await invalidateCache(redis, collectedAt);

  } catch (error) {
    await connection.rollback();
    console.error('âŒ Error saving articles, rolled back:', error);
    throw error;
  } finally {
    connection.release();
  }
}

/**
 * íŠ¹ì • ì‹œê°„ì˜ ê¸°ì‚¬ ìºì‹œ ë¬´íš¨í™”
 *
 * @param redis - Redis ìºì‹œ ì¸ìŠ¤í„´ìŠ¤
 * @param collectedAt - ìˆ˜ì§‘ ì‹œê°„
 */
async function invalidateCache(redis: any, collectedAt: string): Promise<void> {
  try {
    // í•´ë‹¹ ì‹œê°„ì˜ ëª¨ë“  ìºì‹œ í‚¤ ì‚­ì œ
    const pattern = `articles:*${collectedAt}*`;
    const keys = await redis.keys(pattern);

    if (keys.length > 0) {
      await redis.deleteMany(keys);
      console.log(`ğŸ—‘ï¸  Invalidated ${keys.length} cache entries for ${collectedAt}`);
    }

    // latest_collected_at ìºì‹œë„ ë¬´íš¨í™”
    await redis.delete('articles:latest_collected_at');
  } catch (error) {
    console.error('âš ï¸  Failed to invalidate cache:', error);
    // ìºì‹œ ë¬´íš¨í™” ì‹¤íŒ¨ëŠ” ì¹˜ëª…ì ì´ì§€ ì•Šìœ¼ë¯€ë¡œ throwí•˜ì§€ ì•ŠìŒ
  }
}

/**
 * MySQL ì—°ê²° í…ŒìŠ¤íŠ¸
 *
 * @returns ì—°ê²° ì„±ê³µ ì—¬ë¶€
 */
export async function testMySQLConnection(): Promise<boolean> {
  try {
    const pool = getDatabasePool();
    const connection = await pool.getConnection();
    await connection.ping();
    connection.release();
    return true;
  } catch (error) {
    console.error('âŒ MySQL connection test failed:', error);
    return false;
  }
}

/**
 * Redis ì—°ê²° í…ŒìŠ¤íŠ¸
 *
 * @returns ì—°ê²° ì„±ê³µ ì—¬ë¶€
 */
export async function testRedisConnection(): Promise<boolean> {
  try {
    const redis = getRedisCache();
    const client = redis.getClient();
    await client.ping();
    return true;
  } catch (error) {
    console.error('âŒ Redis connection test failed:', error);
    return false;
  }
}
